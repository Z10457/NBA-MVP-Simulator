{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import chromedriver_autoinstaller #removed need to manually download chromeDriver\n",
    "\n",
    "import os #interacts with the operating systems ( such as creating folders/checking files)\n",
    "import pandas as pd #used to read and clean the data \n",
    "import shutil #copying/moving files or directories\n",
    "#from selenium import webdriver #this is all for the automating the web browsers \n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from selenium.webdriver.common.by import By\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver.support import expected_conditions as EC\n",
    "import time #helps avoid overloading web requests.\n",
    "from bs4 import BeautifulSoup as bs #extract info such as player stats from a table.\n",
    "import requests #requests usd to get HTML pages\n",
    "import warnings; warnings.filterwarnings(\"ignore\") #suppress python warnings, may remove this though\n",
    "\n",
    "# unhide all rows and columns #below adjusts how the data is displayed.\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = list(range(2015, 2025)) #this has set the year range for the data from 2015 to 2024\n",
    "#url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\"\n",
    "\n",
    "\n",
    "#all_data = [] #this is where the data goes to, variable\n",
    "\n",
    "#for year in years:\n",
    "    #url = url_start.format(year)\n",
    "    #data = requests.get(url)\n",
    "\n",
    "    #with open(\"./{}.html\".format(year), \"w+\") as f:\n",
    "        #f.write(data.text)\n",
    "    \n",
    "    #with open(\"./{}.html\".format(year)) as f:\n",
    "        #page = f.read()\n",
    "        \n",
    "    #soup = bs(page, \"html.parser\")\n",
    "    #soup.find(\"tr\", class_ = \"over_header\").decompose()\n",
    "    #mvp_table = soup.find_all(id = \"mvp\")\n",
    "    #mvp = pd.read_html(str(mvp_table))[0]\n",
    "    #mvp[\"Year\"] = year\n",
    "    \n",
    "    #all_data.append(mvp)\n",
    "    #mvps = pd.concat(all_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season   Lg                   Player Voting  Age   Tm   G    MP   PTS   TRB   AST  STL  BLK    FG%    3P%    FT%    WS  WS/48\n",
      "1   2024-25  NBA  Shai Gilgeous-Alexander    (V)   26  OKC  76  34.2  32.7   5.0   6.4  1.7  1.0  0.519  0.375  0.898  16.7  0.309\n",
      "2   2023-24  NBA            Nikola JokiÄ    (V)   28  DEN  79  34.6  26.4  12.4   9.0  1.4  0.9  0.583  0.359  0.817  17.0  0.299\n",
      "3   2022-23  NBA              Joel Embiid    (V)   28  PHI  66  34.6  33.1  10.2   4.2  1.0  1.7  0.548  0.330  0.857  12.3  0.259\n",
      "4   2021-22  NBA            Nikola JokiÄ    (V)   26  DEN  74  33.5  27.1  13.8   7.9  1.5  0.9  0.583  0.337  0.810  15.2  0.296\n",
      "5   2020-21  NBA            Nikola JokiÄ    (V)   25  DEN  72  34.6  26.4  10.8   8.3  1.3  0.7  0.566  0.388  0.868  15.6  0.301\n",
      "6   2019-20  NBA    Giannis Antetokounmpo    (V)   25  MIL  63  30.4  29.5  13.6   5.6  1.0  1.0  0.553  0.304  0.633  11.1  0.279\n",
      "7   2018-19  NBA    Giannis Antetokounmpo    (V)   24  MIL  72  32.8  27.7  12.5   5.9  1.3  1.5  0.578  0.256  0.729  14.4  0.292\n",
      "8   2017-18  NBA             James Harden    (V)   28  HOU  72  35.4  30.4   5.4   8.8  1.8  0.7  0.449  0.367  0.858  15.4  0.289\n",
      "9   2016-17  NBA        Russell Westbrook    (V)   28  OKC  81  34.6  31.6  10.7  10.4  1.6  0.4  0.425  0.343  0.845  13.1  0.224\n",
      "10  2015-16  NBA            Stephen Curry    (V)   27  GSW  79  34.2  30.1   5.4   6.7  2.1  0.2  0.504  0.454  0.908  17.9  0.318\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.basketball-reference.com/awards/mvp.html#mvp_NBA\" #this is the web page we want to scrape\n",
    "data = requests.get(url) #sends a GET request to the server and gets the pages html, and the content from the html page is stored now in data \n",
    "soup = bs(data.text, \"html.parser\") #converts the text into smth that is searchable now\n",
    "\n",
    "table = soup.find('table', id='mvp_NBA') \n",
    "\n",
    "mvp_df = pd.read_html(str(table), header=1)[0]\n",
    "\n",
    "mvp_df.columns = [col.strip() for col in mvp_df.columns] \n",
    "\n",
    "#mvp_df = mvp_df.dropna(subset=[mvp_df.columns[0]])\n",
    "mvp_df = mvp_df[mvp_df['Season'].astype(str).str[:4].astype(int) >= 2015]\n",
    "\n",
    "#mvp_df.columns = ['Seasons', 'Players']\n",
    "\n",
    "mvp_df = mvp_df.reset_index(drop=True)\n",
    "mvp_df.index = mvp_df.index + 1 #now instead of starting at 0 it will start at 1\n",
    "\n",
    "print (mvp_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#table = soup.find('table', id = 'mvp_NBA') #searches the HTML for the 1st element that matches the criteria, ps table means we are looking for an HTML element\n",
    "#mvp_df = pd.read_html(str(table))[0] #with this mvp_df is a pandas data frame containing ALL the mvp data\n",
    "#mvp_df.columns = [\n",
    "    #''.join(col).strip() if isinstance(col,tuple) else col.strip()\n",
    "    #for col in mvp_df.columns]\n",
    "\n",
    "#mvp_df = mvp_df[mvp_df['Season'].astype(str).str[:4].astype(int) >=2016] #this filters for the 2016 mvp\n",
    "\n",
    "#mvp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mvps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmvps\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mvps' is not defined"
     ]
    }
   ],
   "source": [
    "mvps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/.../chromedriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[1;32m      4\u001b[0m     url \u001b[38;5;241m=\u001b[39m player_stats_url\u001b[38;5;241m.\u001b[39mformat(year)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"/Users/.../chromedriver\")\n",
    "\n",
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "    \n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    with open(\"player/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'player/2015.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.html\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         page \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/nba_project/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'player/2015.html'"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    with open(\"player/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    player_table = soup.find_all(id=\"per_game_stats\")[0]\n",
    "    player_all_data = pd.read_html(str(player_table))[0]\n",
    "    player_all_data[\"Year\"] = year\n",
    "    all_data.append(player_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.concat(all_data)\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    \n",
    "    data = requests.get(url)\n",
    "    \n",
    "    with open(\"team/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for year in years:\n",
    "    with open(\"team/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    e_table = soup.find_all(id=\"divs_standings_E\")[0]\n",
    "    e_df = pd.read_html(str(e_table))[0]\n",
    "    e_df[\"Year\"] = year\n",
    "    e_df[\"Team\"] = e_df[\"Eastern Conference\"]\n",
    "    del e_df[\"Eastern Conference\"]\n",
    "    all_data.append(e_df)\n",
    "    \n",
    "    w_table = soup.find_all(id=\"divs_standings_W\")[0]\n",
    "    w_df = pd.read_html(str(w_table))[0]\n",
    "    w_df[\"Year\"] = year\n",
    "    w_df[\"Team\"] = w_df[\"Western Conference\"]\n",
    "    del w_df[\"Western Conference\"]\n",
    "    all_data.append(w_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(all_data)\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv(\"teams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
